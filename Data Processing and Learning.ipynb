{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T17:53:56.755939Z",
     "start_time": "2017-06-19T17:53:52.584372Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import h5py\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import glob\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import train\n",
    "from random import shuffle\n",
    "import imp\n",
    "import os\n",
    "from PIL import Image, ImageFont, ImageDraw, ImageEnhance\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T19:03:19.344136Z",
     "start_time": "2017-06-19T19:03:19.215728Z"
    }
   },
   "outputs": [],
   "source": [
    "characters = [k.split('/')[2] for k in glob.glob('./characters/*') if len([p for p in glob.glob(k+'/*') if 'edited' in p or 'pic_vid' in p]) > 290]\n",
    "map_characters = dict(enumerate(characters))\n",
    "map_characters = {0: 'abraham_grampa_simpson', 1: 'apu_nahasapeemapetilon', 2: 'bart_simpson', \n",
    "        3: 'charles_montgomery_burns', 4: 'chief_wiggum', 5: 'comic_book_guy', 6: 'edna_krabappel', \n",
    "        7: 'homer_simpson', 8: 'kent_brockman', 9: 'krusty_the_clown', 10: 'lisa_simpson', \n",
    "        11: 'marge_simpson', 12: 'milhouse_van_houten', 13: 'moe_szyslak', \n",
    "        14: 'ned_flanders', 15: 'nelson_muntz', 16: 'principal_skinner', 17: 'sideshow_bob'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T18:01:59.364496Z",
     "start_time": "2017-06-19T18:01:02.635237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (14317, 64, 64, 3) (14317, 18)\n",
      "Test (2527, 64, 64, 3) (2527, 18)\n",
      "bart_simpson : 1028 train pictures & 148 test pictures\n",
      "lisa_simpson : 1018 train pictures & 158 test pictures\n",
      "charles_montgomery_burns : 1010 train pictures & 166 test pictures\n",
      "homer_simpson : 1010 train pictures & 166 test pictures\n",
      "moe_szyslak : 1007 train pictures & 169 test pictures\n",
      "marge_simpson : 998 train pictures & 178 test pictures\n",
      "principal_skinner : 996 train pictures & 180 test pictures\n",
      "krusty_the_clown : 982 train pictures & 194 test pictures\n",
      "ned_flanders : 974 train pictures & 202 test pictures\n",
      "milhouse_van_houten : 890 train pictures & 189 test pictures\n",
      "chief_wiggum : 854 train pictures & 132 test pictures\n",
      "abraham_grampa_simpson : 788 train pictures & 125 test pictures\n",
      "sideshow_bob : 745 train pictures & 132 test pictures\n",
      "apu_nahasapeemapetilon : 526 train pictures & 97 test pictures\n",
      "kent_brockman : 429 train pictures & 69 test pictures\n",
      "edna_krabappel : 385 train pictures & 72 test pictures\n",
      "comic_book_guy : 380 train pictures & 89 test pictures\n",
      "nelson_muntz : 297 train pictures & 61 test pictures\n"
     ]
    }
   ],
   "source": [
    "imp.reload(train)\n",
    "## Just creating dataset\n",
    "X_train, X_test, y_train, y_test = train.get_dataset(save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Four convulational layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Same pictures training/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T21:03:04.590942Z",
     "start_time": "2017-06-19T21:02:37.945205Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (14317, 64, 64, 3) (14317, 18)\n",
      "Test (2527, 64, 64, 3) (2527, 18)\n",
      "bart_simpson : 1017 train pictures & 159 test pictures\n",
      "principal_skinner : 1011 train pictures & 165 test pictures\n",
      "marge_simpson : 1006 train pictures & 170 test pictures\n",
      "lisa_simpson : 999 train pictures & 177 test pictures\n",
      "ned_flanders : 994 train pictures & 182 test pictures\n",
      "charles_montgomery_burns : 993 train pictures & 183 test pictures\n",
      "krusty_the_clown : 993 train pictures & 183 test pictures\n",
      "homer_simpson : 987 train pictures & 189 test pictures\n",
      "moe_szyslak : 981 train pictures & 195 test pictures\n",
      "milhouse_van_houten : 926 train pictures & 153 test pictures\n",
      "chief_wiggum : 854 train pictures & 132 test pictures\n",
      "abraham_grampa_simpson : 778 train pictures & 135 test pictures\n",
      "sideshow_bob : 749 train pictures & 128 test pictures\n",
      "apu_nahasapeemapetilon : 523 train pictures & 100 test pictures\n",
      "kent_brockman : 432 train pictures & 66 test pictures\n",
      "comic_book_guy : 390 train pictures & 79 test pictures\n",
      "edna_krabappel : 372 train pictures & 85 test pictures\n",
      "nelson_muntz : 312 train pictures & 46 test pictures\n",
      "WARNING:tensorflow:From /home/cenk/.virtualenvs/simpson/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/cenk/.virtualenvs/simpson/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/cenk/.virtualenvs/simpson/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/40\n",
      "447/447 [==============================] - 14s 31ms/step - loss: 14.9777 - acc: 0.0690 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 2/40\n",
      "447/447 [==============================] - 13s 28ms/step - loss: 15.0003 - acc: 0.0694 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 3/40\n",
      "447/447 [==============================] - 13s 28ms/step - loss: 15.0048 - acc: 0.0691 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 4/40\n",
      "447/447 [==============================] - 13s 28ms/step - loss: 15.0054 - acc: 0.0690 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 5/40\n",
      "447/447 [==============================] - 12s 28ms/step - loss: 14.9885 - acc: 0.0701 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 6/40\n",
      "447/447 [==============================] - 13s 28ms/step - loss: 15.0059 - acc: 0.0690 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 7/40\n",
      "447/447 [==============================] - 12s 28ms/step - loss: 15.0009 - acc: 0.0693 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 8/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 14.9992 - acc: 0.0694 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 9/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 14.9998 - acc: 0.0694 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 10/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 15.0003 - acc: 0.0694 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 11/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 15.0088 - acc: 0.0688 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 12/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 15.0015 - acc: 0.0693 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 13/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 15.0014 - acc: 0.0693 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 14/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 14.9930 - acc: 0.0698 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 15/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 15.0088 - acc: 0.0688 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 16/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 14.9919 - acc: 0.0699 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 17/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 15.0116 - acc: 0.0687 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 18/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 14.9869 - acc: 0.0702 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 19/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 15.0032 - acc: 0.0692 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 20/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 14.9869 - acc: 0.0702 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 21/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 15.0116 - acc: 0.0687 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 22/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 14.9964 - acc: 0.0696 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 23/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 15.0065 - acc: 0.0690 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 24/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 14.9976 - acc: 0.0695 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 25/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 14.9862 - acc: 0.0702 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 26/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 14.9969 - acc: 0.0696 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 27/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 15.0116 - acc: 0.0686 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 28/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 14.9964 - acc: 0.0696 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 29/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 15.0009 - acc: 0.0693 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 30/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 14.9992 - acc: 0.0694 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 31/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 15.0026 - acc: 0.0692 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 32/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 14.9969 - acc: 0.0696 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 33/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 15.0104 - acc: 0.0687 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 34/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 14.9908 - acc: 0.0699 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 35/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 14.9772 - acc: 0.0708 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 36/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 15.0161 - acc: 0.0684 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 37/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 14.9851 - acc: 0.0703 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 38/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 15.0381 - acc: 0.0670 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 39/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 14.9947 - acc: 0.0697 - val_loss: 14.9509 - val_acc: 0.0724\n",
      "Epoch 40/40\n",
      "447/447 [==============================] - 12s 27ms/step - loss: 14.9631 - acc: 0.0717 - val_loss: 14.9509 - val_acc: 0.0724\n"
     ]
    }
   ],
   "source": [
    "# Training in the notebook\n",
    "X_train, X_test, y_train, y_test = train.get_dataset()\n",
    "model, opt = train.create_model_four_conv(X_train.shape[1:])\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "               optimizer=opt,\n",
    "               metrics=['accuracy'])\n",
    "model, history = train.training(model, X_train, X_test, y_train, y_test, \n",
    "                                data_augmentation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training on AWS\n",
    "#X_train, X_test, y_train, y_test = train.get_dataset(load=True)\n",
    "#model = keras.models.load_model('./models/model_08_06.h5')\n",
    "#with open('./models/history06_19.pkl', 'rb') as f:\n",
    "#    history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "  abraham_grampa_simpson       0.00      0.00      0.00       135\n",
      "  apu_nahasapeemapetilon       0.00      0.00      0.00       100\n",
      "            bart_simpson       0.00      0.00      0.00       159\n",
      "charles_montgomery_burns       0.00      0.00      0.00       183\n",
      "            chief_wiggum       0.00      0.00      0.00       132\n",
      "          comic_book_guy       0.00      0.00      0.00        79\n",
      "          edna_krabappel       0.00      0.00      0.00        85\n",
      "           homer_simpson       0.00      0.00      0.00       189\n",
      "           kent_brockman       0.00      0.00      0.00        66\n",
      "        krusty_the_clown       0.07      1.00      0.14       183\n",
      "            lisa_simpson       0.00      0.00      0.00       177\n",
      "           marge_simpson       0.00      0.00      0.00       170\n",
      "     milhouse_van_houten       0.00      0.00      0.00       153\n",
      "             moe_szyslak       0.00      0.00      0.00       195\n",
      "            ned_flanders       0.00      0.00      0.00       182\n",
      "            nelson_muntz       0.00      0.00      0.00        46\n",
      "       principal_skinner       0.00      0.00      0.00       165\n",
      "            sideshow_bob       0.00      0.00      0.00       128\n",
      "\n",
      "               micro avg       0.07      0.07      0.07      2527\n",
      "               macro avg       0.00      0.06      0.01      2527\n",
      "            weighted avg       0.01      0.07      0.01      2527\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cenk/.virtualenvs/simpson/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Loading from callbacks\n",
    "#imp.reload(train)\n",
    "#model = train.load_model_from_checkpoint('./models/weights.best_6conv2.hdf5', six_conv=True)\n",
    "y_pred = model.predict(X_test)\n",
    "print('\\n', sklearn.metrics.classification_report(np.where(y_test > 0)[1], \n",
    "                                                  np.argmax(y_pred, axis=1), \n",
    "                                                  target_names=list(map_characters.values())), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-13T22:50:43.174450Z",
     "start_time": "2017-06-13T22:50:42.521287Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'History' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f72273bb58c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'History' object is not subscriptable"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs= range(200)\n",
    "f, ax = plt.subplots(ncols=2, figsize=(15,6))\n",
    "ax[0].plot(epochs, history['loss'], label='loss')\n",
    "ax[0].plot(epochs, history['val_loss'], label='val_loss')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend()\n",
    "ax[1].plot(epochs, history['acc'], label='acc')\n",
    "ax[1].plot(epochs, history['val_acc'], label='val_acc')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T22:07:18.729151Z",
     "start_time": "2017-06-19T22:07:18.310283Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./models/history06_19.pkl', 'rb') as f:\n",
    "    history = pickle.load(f)\n",
    "epochs= range(40)\n",
    "f, ax = plt.subplots(ncols=2, figsize=(15,6))\n",
    "ax[0].plot(epochs, history['loss'], label='loss')\n",
    "ax[0].plot(epochs, history['val_loss'], label='val_loss')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend()\n",
    "ax[1].plot(epochs, history['acc'], label='acc')\n",
    "ax[1].plot(epochs, history['val_acc'], label='val_acc')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T20:35:26.924628Z",
     "start_time": "2017-06-19T20:35:26.464445Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "cnf_matrix = sklearn.metrics.confusion_matrix(np.where(y_test > 0)[1], np.argmax(y_pred, axis=1))\n",
    "classes = list(map_characters.values())\n",
    "plt.imshow(cnf_matrix, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "_ = plt.xticks(tick_marks, classes, rotation=90)\n",
    "_ = plt.yticks(tick_marks, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### With BGR/RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-05T23:18:19.686606Z",
     "start_time": "2017-06-05T23:18:08.010096Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_test2 = []\n",
    "for img in X_test:\n",
    "    X_test2.append(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "X_test2 = np.array(X_test2)\n",
    "model = keras.models.load_model('./models/model_BGR.h5')\n",
    "y_pred = model.predict(X_test2)\n",
    "print('\\n', sklearn.metrics.classification_report(np.where(y_test > 0)[1], \n",
    "                                                  np.argmax(y_pred, axis=1), \n",
    "                                                  target_names=list(map_characters.values())), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Six convolutional layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T20:54:51.966888Z",
     "start_time": "2017-06-01T20:54:44.048799Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Training on AWS\n",
    "X_train, X_test, y_train, y_test = train.get_dataset(load=True)\n",
    "model = keras.models.load_model('./models/model_sixconv.h5')\n",
    "with open('./models/history2.pkl', 'rb') as f:\n",
    "    history = pickle.load(f)\n",
    "y_pred = model.predict(X_test)\n",
    "print('\\n', sklearn.metrics.classification_report(np.where(y_test > 0)[1], \n",
    "                                                  np.argmax(y_pred, axis=1), \n",
    "                                                  target_names=list(map_characters.values())), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T20:55:11.635466Z",
     "start_time": "2017-06-01T20:55:11.026225Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epochs= range(40)\n",
    "f, ax = plt.subplots(ncols=2, figsize=(15,6))\n",
    "ax[0].plot(epochs, history['loss'], label='loss')\n",
    "ax[0].plot(epochs, history['val_loss'], label='val_loss')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend()\n",
    "ax[1].plot(epochs, history['acc'], label='acc')\n",
    "ax[1].plot(epochs, history['val_acc'], label='val_acc')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T20:55:35.385798Z",
     "start_time": "2017-06-01T20:55:35.383200Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## -> More overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Predict from url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T23:48:06.070059Z",
     "start_time": "2017-05-31T23:48:06.050821Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "def url_to_image(url):\n",
    "    resp = urllib.request.urlopen(url)\n",
    "    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    return image\n",
    "\n",
    "def plot_and_predict(url, all_perc=False):\n",
    "    image = url_to_image(url)\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    pic = cv2.resize(image, (pic_size,pic_size))\n",
    "    a = model.predict_proba(pic.reshape(1, pic_size, pic_size,3))[0]\n",
    "    if all_perc:\n",
    "        print('\\n'.join(['{} : {}%'.format(map_characters[i], round(k*100)) for i,k in sorted(enumerate(a), key=lambda x:x[1], reverse=True)]))\n",
    "    else:\n",
    "        return map_characters[np.argmax(a)].replace('_',' ').title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T23:49:55.637079Z",
     "start_time": "2017-05-31T23:49:55.256220Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "url = \"https://vignette3.wikia.nocookie.net/simpsons/images/2/25/Adult_burns.jpg/revision/latest?cb=20111012170021\"\n",
    "plot_and_predict(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T21:46:10.432344Z",
     "start_time": "2017-06-01T21:46:10.428738Z"
    },
    "collapsed": true
   },
   "source": [
    "#### Generating and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-08T20:00:24.737456Z",
     "start_time": "2017-06-08T20:00:22.193140Z"
    }
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "map_characters = {0: 'abraham_grampa_simpson', 1: 'apu_nahasapeemapetilon', 2: 'bart_simpson', \n",
    "    3: 'charles_montgomery_burns', 4: 'chief_wiggum', 5: 'homer_simpson', \n",
    "    6: 'krusty_the_clown', 7: 'lisa_simpson', 8: 'marge_simpson', \n",
    "    9: 'milhouse_van_houten', 10: 'moe_szyslak', 11: 'ned_flanders', \n",
    "    12: 'principal_skinner', 13: 'sideshow_bob'}\n",
    "\n",
    "F = plt.figure(1, (15,20))\n",
    "grid = AxesGrid(F, 111,  # similar to subplot(141)\n",
    "                nrows_ncols=(3, 4),\n",
    "                axes_pad=0,\n",
    "                label_mode=\"1\")\n",
    "\n",
    "for i in range(12):\n",
    "    char = map_characters[i]\n",
    "    image = cv2.imread(np.random.choice([k for k in glob.glob('./characters/%s/*' % char) if 'pic_vid' in k]))\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    pic = cv2.resize(image, (64, 64)).astype('float32') / 255.\n",
    "    a = model.predict(pic.reshape(1, 64, 64,3))[0]\n",
    "    actual = char.split('_')[0].title()\n",
    "#     pred = map_characters[np.argmax(a)].split('_')[0].title()\n",
    "    text = sorted(['{:s} : {:.1f}%'.format(map_characters[k].split('_')[0].title(), 100*v) for k,v in enumerate(a)], \n",
    "       key=lambda x:float(x.split(':')[1].split('%')[0]), reverse=True)[:3]\n",
    "    img = cv2.resize(img, (352, 352))\n",
    "    cv2.rectangle(img, (0,260),(215,352),(255,255,255), -1)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(img, 'Actual : %s' % actual, (10, 280), font, 0.7,(0,0,0),2,cv2.LINE_AA)\n",
    "    for k, t in enumerate(text):\n",
    "        cv2.putText(img, t,(10, 300+k*18), font, 0.65,(0,0,0),2,cv2.LINE_AA)\n",
    "#     cv2.putText(img, 'Pred : %s' % pred, (100, 310), font, 0.7,(0,0,0),2,cv2.LINE_AA)    \n",
    "    grid[i].imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Finding a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-13T22:54:54.679573Z",
     "start_time": "2017-06-13T22:54:41.559035Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, verbose=0)\n",
    "comp = np.argmax(y_test, axis=1) == np.argmax(y_pred, axis=1)\n",
    "index_good, index_false = [i for i, x in enumerate(comp) if x], [i for i, x in enumerate(comp) if not x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-13T22:55:17.358441Z",
     "start_time": "2017-06-13T22:55:17.344109Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "max_good = np.max(y_pred[index_good], axis=1)\n",
    "max_wrong = np.max(y_pred[index_false], axis=1)\n",
    "diff_good = np.diff(np.sort(y_pred[index_good], axis=1)[:, 16:])\n",
    "diff_wrong = np.diff(np.sort(y_pred[index_false], axis=1)[:, 16:])\n",
    "std_good = np.std(y_pred[index_good], axis=1)\n",
    "std_wrong = np.std(y_pred[index_false], axis=1)\n",
    "\n",
    "print(\"For good predictions : Max : {:.2f}, Difference Two First : {:.3f}, STD : {:.2f}\".format(np.mean(max_good),\n",
    "                                                                            np.mean(diff_good),\n",
    "                                                                            np.mean(std_good)))\n",
    "print(\"For wrong predictions : Max : {:.2f}, Difference Two First : {:.3f}, STD : {:.2f}\".format(np.mean(max_wrong),\n",
    "                                                                             np.mean(diff_wrong),\n",
    "                                                                            np.mean(std_wrong)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-13T22:55:19.136648Z",
     "start_time": "2017-06-13T22:55:18.400437Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(ncols=3, figsize=(19,6))\n",
    "ax[0].scatter(x = diff_good, y= max_good, c='red', marker='+', label = 'good pred')\n",
    "ax[0].scatter(x = diff_wrong, y= max_wrong, c='green', marker='o', label = 'wrong pred')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel('Probability difference between the 2 best candidates')\n",
    "ax[0].set_ylabel('Probability of the best prediction')\n",
    "\n",
    "ax[1].scatter(x = diff_good, y= std_good, c='red', marker='+', label = 'good pred')\n",
    "ax[1].scatter(x = diff_wrong, y= std_wrong, c='green', marker='o', label = 'wrong pred')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel('Probability difference between the 2 best candidates')\n",
    "ax[1].set_ylabel('Standard deviation of the prediction')\n",
    "\n",
    "ax[2].scatter(x = max_good, y= std_good, c='red', marker='+', label = 'good pred')\n",
    "ax[2].scatter(x = max_wrong, y= std_wrong, c='green', marker='o', label = 'wrong pred')\n",
    "ax[2].legend()\n",
    "ax[2].set_xlabel('Probability of the best prediction')\n",
    "ax[2].set_ylabel('Standard deviation of the prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-13T22:53:23.345840Z",
     "start_time": "2017-06-13T22:53:23.333754Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## FOR LISA\n",
    "id_lisa = 10\n",
    "index_lisa = [i for i, x in enumerate(np.argmax(y_pred, axis= 1) == id_lisa) if x]\n",
    "index_good_lisa, index_wrong_lisa = [k for k in index_lisa if k in index_good], [k for k in index_lisa if k in index_false]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-13T22:53:42.314000Z",
     "start_time": "2017-06-13T22:53:41.741370Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dicts = {'max':{'good':np.max(y_pred[index_good_lisa], axis=1), \n",
    "                'wrong': np.max(y_pred[index_wrong_lisa], axis=1)},\n",
    "        'diff':{'good':np.diff(np.sort(y_pred[index_good_lisa], axis=1)[:, 16:]), \n",
    "                'wrong': np.diff(np.sort(y_pred[index_wrong_lisa], axis=1)[:, 16:])}, \n",
    "        'std':{'good': np.std(y_pred[index_good_lisa], axis=1), \n",
    "                'wrong': np.std(y_pred[index_wrong_lisa], axis=1)}}\n",
    "\n",
    "import itertools\n",
    "chosen = list(itertools.combinations(dicts.items(),2))\n",
    "f, ax = plt.subplots(ncols=3, figsize=(19,6))\n",
    "for i in range(3):\n",
    "    ax[i].scatter(x = chosen[i][0][1]['good'], y= chosen[i][1][1]['good'], \n",
    "                  c='red', marker='+', label = 'good pred')\n",
    "    ax[i].scatter(x = chosen[i][0][1]['wrong'], y= chosen[i][1][1]['wrong'], \n",
    "                  c='green', marker='o', label = 'wrong pred')\n",
    "    ax[i].legend()\n",
    "    ax[i].set_xlabel(chosen[i][0][0])\n",
    "    ax[i].set_ylabel(chosen[i][1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threshold and Precision/Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T00:18:50.913476Z",
     "start_time": "2017-06-14T00:18:38.064770Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, verbose=0)\n",
    "indices = [round(k*0.01,2) for k in range(0, 100, 5)] + [0.99]\n",
    "pos_characters = {cl: {k:[] for k in indices} for cl in map_characters}\n",
    "for k in indices:\n",
    "    for i, e in enumerate(y_pred):\n",
    "        if np.max(e) > k:\n",
    "            pos_characters[np.argmax(e)][k].append(int(np.argmax(e) == np.argmax(y_test[i])))\n",
    "pos_characters['ALL'] = {k:np.sum([pos_characters[cl][k] for cl in pos_characters]) for k in indices}                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T01:05:43.502988Z",
     "start_time": "2017-06-14T01:05:41.869969Z"
    }
   },
   "outputs": [],
   "source": [
    "indices = [round(k*0.01, 2)+round(p*0.01,2) for k,p in zip(range(0, 20), range(0, 100, 5))]\n",
    "pos_characters_2 = {cl: {k:[] for k in indices} for cl in map_characters}\n",
    "for k in indices:\n",
    "    for i, e in enumerate(y_pred):\n",
    "        if np.std(e)+np.max(e) > k:\n",
    "            pos_characters_2[np.argmax(e)][k].append(int(np.argmax(e) == np.argmax(y_test[i])))\n",
    "pos_characters_2['ALL'] = {k:np.sum([pos_characters_2[cl][k] for cl in pos_characters_2]) for k in indices}                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T00:41:08.113571Z",
     "start_time": "2017-06-14T00:41:07.066020Z"
    }
   },
   "outputs": [],
   "source": [
    "classes_plot = [\"ALL\", 10, 7, 15, 2, 11]\n",
    "tr = {\"ALL\": np.argmax(y_test, axis=1)}\n",
    "f, ax = plt.subplots(ncols=len(classes_plot), figsize=(len(classes_plot)*5, 5))\n",
    "for i, cl_plt in enumerate(classes_plot):\n",
    "    precision = {k:np.sum(pos_characters[cl_plt][k])/len(pos_characters[cl_plt][k]) for k in indices}\n",
    "    recall = {k:np.sum(pos_characters[cl_plt][k])/np.sum(np.argmax(y_test, axis=1)==tr.get(cl_plt, cl_plt))for k in indices}\n",
    "    f1_score = {k:(2*precision[k]*recall[k])/(precision[k]+recall[k]) for k in indices}\n",
    "    x,y = zip(*sorted(precision.items()))\n",
    "    ax[i].plot(x, y, color='blue', label='Precision')\n",
    "    x,y = zip(*sorted(recall.items()))\n",
    "    ax[i].plot(x, y, label='Recall', color='green')\n",
    "    x,y = zip(*sorted(f1_score.items()))\n",
    "    ax[i].plot(x, y, color='red', label='F1 Score')\n",
    "    _ = ax[i].set_xlim((0,1))\n",
    "    _ = ax[i].set_ylabel('Score')\n",
    "    _ = ax[i].set_xlabel('Threshold (Probability minimum for predicted class)')\n",
    "    _ = ax[i].set_ylim((0.3,1))\n",
    "    _ = ax[i].legend()\n",
    "    _ = ax[i].set_title('Class : %s \\n(Test set size : %d)' % (map_characters.get(cl_plt, cl_plt), np.sum(np.argmax(y_test, axis=1) == tr.get(cl_plt, cl_plt))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Attention maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-09T23:35:47.084345Z",
     "start_time": "2017-06-09T23:35:42.120419Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "from vis.utils import utils\n",
    "from vis.visualization import visualize_saliency\n",
    "\n",
    "# The name of the layer we want to visualize\n",
    "# (see model definition in vggnet.py)\n",
    "layer_idx = [idx for idx, layer in enumerate(model.layers)][16]\n",
    "\n",
    "# Images corresponding to tiger, penguin, dumbbell, speedboat, spider\n",
    "image_paths = np.random.choice(np.concatenate([glob.glob('./characters/%s/*.jpg' % k) for k in map_characters.values()]), 3)\n",
    "\n",
    "heatmaps = []\n",
    "true_img = []\n",
    "d=[]\n",
    "for path in image_paths:\n",
    "    seed_img = utils.load_img(path, target_size=(64, 64)).astype('float32') / 255.\n",
    "    seed_img  = seed_img.reshape((1, 64, 64, 3))\n",
    "    pred_class = np.argmax(model.predict(seed_img))\n",
    "\n",
    "    # Here we are asking it to show attention such that prob of `pred_class` is maximized.\n",
    "    heatmap = visualize_saliency(model, layer_idx, [pred_class], seed_img.reshape((64, 64, 3)))\n",
    "    heatmaps.append(heatmap * 255.) \n",
    "    true_img.append(cv2.resize(cv2.imread(path),(480,640)))\n",
    "    d.append(cv2.resize(cv2.imread(path),(480,640)) + cv2.resize(heatmap,(480,640)))\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.axis('off')\n",
    "plt.imshow(utils.stitch_images(true_img))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.axis('off')\n",
    "plt.imshow(utils.stitch_images(d))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true
   },
   "source": [
    "#### Create video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-12T23:35:07.383218Z",
     "start_time": "2017-06-12T23:35:06.988568Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m, s = 5, 7\n",
    "cap = cv2.VideoCapture(\"video1.avi\") \n",
    "nb_frames = 2500\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "cap.set(1, fps*(m*60+s))\n",
    "for i in range(4000):\n",
    "    ret, frame = cap.read()\n",
    "    if i % 15 == 0:\n",
    "        img = cv2.resize(frame, (64, 64)).astype('float32') / 255.\n",
    "        a = model.predict(img.reshape((-1, 64, 64, 3)), verbose=0)[0]\n",
    "        text = sorted(['{:s} : {:.1f}%'.format(map_characters[k].split('_')[0].title(), 100*v) for k,v in enumerate(a)], \n",
    "               key=lambda x:float(x.split(':')[1].split('%')[0]), reverse=True)[:3]\n",
    "    im = frame\n",
    "    cv2.rectangle(im, (int(frame.shape[1] * 0.6),int(frame.shape[0] * 0.7)),(frame.shape[1],frame.shape[0]),(255,255,255), -1)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    for k, t in enumerate(text):\n",
    "        cv2.putText(im,t,\n",
    "                    ((int(frame.shape[1] * 0.6 + 10), int(frame.shape[0] * 0.7 + 20 +k*25))), \n",
    "                    font, 0.8,(0,0,0),2,cv2.LINE_AA)\n",
    "    cv2.imwrite('./video_created/vid_{0:0=4d}.jpg'.format(i), im)\n",
    " \n",
    "# !ffmpeg -f image2 -r 25 -i ./video_created/vid_%04d.jpg -vcodec mpeg4 -y ./video_created/movie3.mp4\n",
    "\n",
    "# for i in glob.glob('./video_created/*.jpg'):\n",
    "#     os.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-08T21:15:59.958414Z",
     "start_time": "2017-06-08T21:15:56.756799Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!ffmpeg -f image2 -r 25 -i ./video_created/video_%05d.jpg -vcodec mpeg4 -y ./video_created/movie4.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
